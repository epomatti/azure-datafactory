{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "from notebookutils import mssparkutils"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Load the data filtering by airport_fee."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df = spark.sql(\"select * from Database1.nyc_taxi where airport_fee != 0\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Show the data for troubleshooting."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Write the data to a new parquet."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "parquet_file = \"output/proto.parquet\"\n",
        "\n",
        "if mssparkutils.fs.exists(parquet_file):\n",
        "    mssparkutils.fs.rm(parquet_file, True)\n",
        "\n",
        "df.write.parquet(parquet_file)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "# aaa = mssparkutils.credentials.getConnectionStringOrCreds('synwlitware866-WorkspaceDefaultStorage')\n",
        "# print(aaa)\n",
        "\n",
        "# df.write.parquet(f'abfss://synapse@dlslitware866.dfs.core.windows.net/demo_df.parquet', mode='overwrite')\n",
        "\n",
        "df.write.csv(f'abfss://synapse@dlslitware866.dfs.core.windows.net/demo_df.csv', mode='overwrite')\n"
      ]
    }
  ],
  "metadata": {
    "kernel_info": {
      "name": "synapse_pyspark"
    },
    "kernelspec": {
      "display_name": "Synapse PySpark",
      "language": "Python",
      "name": "synapse_pyspark"
    },
    "language_info": {
      "name": "python"
    },
    "save_output": true,
    "synapse_widget": {
      "state": {},
      "version": "0.1"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
